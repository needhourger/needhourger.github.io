<!doctype html><html lang=zh-CN><head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#"><meta charset=UTF-8><meta name=generator content="Hugo 0.130.0"><meta name=theme-color content="#16171d"><meta name=color-scheme content="light dark"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=format-detection content="telephone=no, date=no, address=no, email=no"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><title>word2vec词向量训练 | Broken Memories</title>
<link rel=stylesheet href=/css/meme.min.d51895fa0ef81a6d301b382c26ceddc7f8b985b30e6b4a2752970f6e5d6d10bc.css><script src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js defer></script><script src=/js/meme.min.862d3ef0c387cd89e33d5a486b12ebbff6e77183d7d42f766d36e91200da66ba.js></script><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto+Serif+SC:wght@400;500;700&amp;family=Source+Code+Pro:ital,wght@0,400;0,700;1,400;1,700&amp;family=Inter:wght@100..900&amp;family=Silkscreen:wght@700&amp;family=Noto+Sans+SC:wght@100..900&amp;family=ZCOOL+QingKe+HuangYou&amp;family=Pixelify+Sans:wght@400..700&amp;display=swap" media=print onload='this.media="all"'><noscript><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto+Serif+SC:wght@400;500;700&amp;family=Source+Code+Pro:ital,wght@0,400;0,700;1,400;1,700&amp;family=Inter:wght@100..900&amp;family=Silkscreen:wght@700&amp;family=Noto+Sans+SC:wght@100..900&amp;family=ZCOOL+QingKe+HuangYou&amp;family=Pixelify+Sans:wght@400..700&amp;display=swap"></noscript><meta name=author content="Yuuki"><meta name=description content=" 概述 最近踩坑机器学习神经网络中的文本处理,所以有了这篇博客.记录一下基于python word2vec训练中文词向量的方法(英文也同样适用) 虽然事后我发现我需要的并不是词向量word2vec,而是训练获得句子向量的方法,权当做个预告吧(咕咕咕)
词向量训练:在自然语言处理中将每个单词映射到一个空间向量过程,从而获得每个词汇之间的关联性.(可能说的不太对,大概就这样吧,不是理论帝)
"><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=mask-icon href=/icons/safari-pinned-tab.svg color=#2a6df4><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-title content="Broken Memories"><meta name=apple-mobile-web-app-status-bar-style content="black"><meta name=mobile-web-app-capable content="yes"><meta name=application-name content="Broken Memories"><meta name=msapplication-starturl content="../../"><meta name=msapplication-TileColor content="#fff"><meta name=msapplication-TileImage content="../../icons/mstile-150x150.png"><link rel=manifest href=/manifest.json><link rel=canonical href=https://yuukisama.cc/code/word2vec%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","datePublished":"2019-03-13T10:26:22+00:00","dateModified":"2024-08-01T07:16:12+00:00","url":"https://yuukisama.cc/code/word2vec%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/","headline":"word2vec词向量训练","description":" 概述 最近踩坑机器学习神经网络中的文本处理,所以有了这篇博客.记录一下基于python word2vec训练中文词向量的方法(英文也同样适用) 虽然事后我发现我需要的并不是词向量word2vec,而是训练获得句子向量的方法,权当做个预告吧(咕咕咕)\n词向量训练:在自然语言处理中将每个单词映射到一个空间向量过程,从而获得每个词汇之间的关联性.(可能说的不太对,大概就这样吧,不是理论帝)\n","inLanguage":"zh-CN","articleSection":"code","wordCount":1026,"image":["https://yuukisama.cc/0.jpg"],"author":{"@type":"Person","description":"Always running on the way ...","email":"chainyuuki@gmail.com","image":"https://yuukisama.cc/icons/apple-touch-icon.png","url":"https://yuukisama.cc/","name":"Yuuki"},"license":"[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh)","publisher":{"@type":"Organization","name":"Broken Memories","logo":{"@type":"ImageObject","url":"https://yuukisama.cc/icons/apple-touch-icon.png"},"url":"https://yuukisama.cc/"},"mainEntityOfPage":{"@type":"WebSite","@id":"https://yuukisama.cc/"}}</script><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@yukiricc"><meta name=twitter:creator content="@yukiricc"><meta property="og:title" content="word2vec词向量训练"><meta property="og:description" content=" 概述 最近踩坑机器学习神经网络中的文本处理,所以有了这篇博客.记录一下基于python word2vec训练中文词向量的方法(英文也同样适用) 虽然事后我发现我需要的并不是词向量word2vec,而是训练获得句子向量的方法,权当做个预告吧(咕咕咕)
词向量训练:在自然语言处理中将每个单词映射到一个空间向量过程,从而获得每个词汇之间的关联性.(可能说的不太对,大概就这样吧,不是理论帝)
"><meta property="og:url" content="https://yuukisama.cc/code/word2vec%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/"><meta property="og:site_name" content="Broken Memories"><meta property="og:locale" content="zh"><meta property="og:image" content="https://yuukisama.cc/0.jpg"><meta property="og:type" content="article"><meta property="article:published_time" content="2019-03-13T10:26:22+00:00"><meta property="article:modified_time" content="2024-08-01T07:16:12+00:00"><meta property="article:section" content="code"><link rel=preconnect href=https://www.google-analytics.com crossorigin><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-YSMKSWDEQK","auto"),ga("send","pageview")</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><div class=container><header class=header><div class=header-wrapper><div class="header-inner single"><div class=site-brand><a href=/ class=brand>Broken Memories</a></div><nav class=nav><ul class=menu id=menu><li class=menu-item><a href><svg viewBox="0 0 512 512" class="icon archive"><path d="M32 448c0 17.7 14.3 32 32 32h384c17.7.0 32-14.3 32-32V160H32v288zm160-212c0-6.6 5.4-12 12-12h104c6.6.0 12 5.4 12 12v8c0 6.6-5.4 12-12 12H204c-6.6.0-12-5.4-12-12v-8zM480 32H32C14.3 32 0 46.3.0 64v48c0 8.8 7.2 16 16 16h480c8.8.0 16-7.2 16-16V64c0-17.7-14.3-32-32-32z"/></svg><span class=menu-item-name>Posts</span></a></li><li class=menu-item><a href=/categories/><svg viewBox="0 0 512 512" class="icon th"><path d="M149.333 56v80c0 13.255-10.745 24-24 24H24c-13.255.0-24-10.745-24-24V56c0-13.255 10.745-24 24-24h101.333c13.255.0 24 10.745 24 24zm181.334 240v-80c0-13.255-10.745-24-24-24H205.333c-13.255.0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256.0 24.001-10.745 24.001-24zm32-240v80c0 13.255 10.745 24 24 24H488c13.255.0 24-10.745 24-24V56c0-13.255-10.745-24-24-24H386.667c-13.255.0-24 10.745-24 24zm-32 80V56c0-13.255-10.745-24-24-24H205.333c-13.255.0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.256.0 24.001-10.745 24.001-24zm-205.334 56H24c-13.255.0-24 10.745-24 24v80c0 13.255 10.745 24 24 24h101.333c13.255.0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24zM0 376v80c0 13.255 10.745 24 24 24h101.333c13.255.0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H24c-13.255.0-24 10.745-24 24zm386.667-56H488c13.255.0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255.0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zm0 160H488c13.255.0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H386.667c-13.255.0-24 10.745-24 24v80c0 13.255 10.745 24 24 24zM181.333 376v80c0 13.255 10.745 24 24 24h101.333c13.255.0 24-10.745 24-24v-80c0-13.255-10.745-24-24-24H205.333c-13.255.0-24 10.745-24 24z"/></svg><span class=menu-item-name>Categories</span></a></li><li class=menu-item><a href=/tags/><svg viewBox="0 0 640 512" class="icon tags"><path d="M497.941 225.941 286.059 14.059A48 48 0 00252.118.0H48C21.49.0.0 21.49.0 48v204.118a48 48 0 0014.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882.0l204.118-204.118c18.745-18.745 18.745-49.137.0-67.882zM112 160c-26.51.0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882.0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397.0h48.721a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137.0 67.882z"/></svg><span class=menu-item-name>Tags</span></a></li><li class=menu-item><a href=/about/><svg viewBox="0 0 496 512" class="icon user-circle"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6.0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7.0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4.0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9s28-2.7 40.9-6.9c2.3-.7 4.7-1.1 7.1-1.1 42.9.0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><span class=menu-item-name>About</span></a></li><li class=menu-item><a id=theme-switcher href=#><svg viewBox="0 0 512 512" class="icon theme-icon-light"><path d="M193.2 104.5 242 7a18 18 0 0128 0l48.8 97.5L422.2 70A18 18 0 01442 89.8l-34.5 103.4L505 242a18 18 0 010 28l-97.5 48.8L442 422.2A18 18 0 01422.2 442l-103.4-34.5L270 505a18 18 0 01-28 0l-48.8-97.5L89.8 442A18 18 0 0170 422.2l34.5-103.4-97.5-48.8a18 18 0 010-28l97.5-48.8L70 89.8A18 18 0 0189.8 70zM256 128a128 128 0 10.01.0M256 160a96 96 0 10.01.0"/></svg><svg viewBox="0 0 512 512" class="icon theme-icon-dark"><path d="M27 412A256 256 0 10181 5a11.5 11.5.0 00-5 20A201.5 201.5.0 0142 399a11.5 11.5.0 00-15 13"/></svg></a></li><li class="menu-item search-item"><form id=search class=search role=search><label for=search-input><svg viewBox="0 0 512 512" class="icon search-icon"><path d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></label>
<input type=search id=search-input class=search-input></form><template id=search-result hidden><article class="content post"><h2 class=post-title><a class=summary-title-link></a></h2><summary class=summary></summary><div class=read-more-container><a class=read-more-link>»</a></div></article></template></li></ul></nav></div></div><input type=checkbox id=nav-toggle aria-hidden=true>
<label for=nav-toggle class=nav-toggle></label>
<label for=nav-toggle class=nav-curtain></label></header><main class="main single" id=main><div class=main-inner><article class="content post h-entry" data-small-caps=true data-align=justify data-type=code data-toc-num=true><h1 class="post-title p-name">word2vec词向量训练</h1><div class=post-meta><time datetime=2019-03-13T10:26:22+00:00 class="post-meta-item published dt-published"><svg viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M148 288h-40c-6.6.0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6.0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6.0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6.0 12 5.4 12 12v52h48c26.5.0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3.0 6-2.7 6-6z"/></svg>&nbsp;2019.3.13</time>
<time datetime=2024-08-01T07:16:12+00:00 class="post-meta-item modified dt-updated"><svg viewBox="0 0 448 512" class="icon post-meta-icon"><path d="M4e2 64h-48V12c0-6.627-5.373-12-12-12h-40c-6.627.0-12 5.373-12 12v52H160V12c0-6.627-5.373-12-12-12h-40c-6.627.0-12 5.373-12 12v52H48C21.49 64 0 85.49.0 112v352c0 26.51 21.49 48 48 48h352c26.51.0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm-6 4e2H54a6 6 0 01-6-6V160h352v298a6 6 0 01-6 6zm-52.849-200.65L198.842 404.519c-4.705 4.667-12.303 4.637-16.971-.068l-75.091-75.699c-4.667-4.705-4.637-12.303.068-16.971l22.719-22.536c4.705-4.667 12.303-4.637 16.97.069l44.104 44.461 111.072-110.181c4.705-4.667 12.303-4.637 16.971.068l22.536 22.718c4.667 4.705 4.636 12.303-.069 16.97z"/></svg>&nbsp;2024.8.1</time>
<span class="post-meta-item category"><svg viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>&nbsp;<a href=/code/ class="category-link p-category">Code</a></span>
<span class="post-meta-item wordcount"><svg viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3.0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9.0l60.1 60.1c18.8 18.7 18.8 49.1.0 67.9zM284.2 99.8 21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3.0-17l-111-111c-4.8-4.7-12.4-4.7-17.1.0zM124.1 339.9c-5.5-5.5-5.5-14.3.0-19.8l154-154c5.5-5.5 14.3-5.5 19.8.0s5.5 14.3.0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8.0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;1026</span>
<span class="post-meta-item reading-time"><svg viewBox="0 0 512 512" class="icon post-meta-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5.0-2e2-89.5-2e2-2e2S145.5 56 256 56s2e2 89.5 2e2 2e2-89.5 2e2-2e2 2e2zm61.8-104.4-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6.0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;3&nbsp;</span>
<span class="post-meta-item busuanzi-page-pv" id=busuanzi_container_page_pv><svg viewBox="0 0 576 512" class="icon post-meta-icon"><path d="M288 144a110.94 110.94.0 00-31.24 5 55.4 55.4.0 017.24 27 56 56 0 01-56 56 55.4 55.4.0 01-27-7.24A111.71 111.71.0 10288 144zm284.52 97.4C518.29 135.59 410.93 64 288 64S57.68 135.64 3.48 241.41a32.35 32.35.0 000 29.19C57.71 376.41 165.07 448 288 448s230.32-71.64 284.52-177.41a32.35 32.35.0 000-29.19zM288 4e2c-98.65.0-189.09-55-237.93-144C98.91 167 189.34 112 288 112s189.09 55 237.93 144C477.1 345 386.66 4e2 288 4e2z"/></svg>&nbsp;<span id=busuanzi_value_page_pv></span></span></div><nav class=contents><h2 id=contents class=contents-title></h2><ol class=toc><li><a id=contents:概述 href=#概述>概述</a></li><li><a id=contents:start href=#start>Start</a></li></ol></nav><div class="post-body e-content"><blockquote><h2 id=概述><a href=#概述 class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href=#contents:概述 class=headings>概述</a></h2></blockquote><ul><li><p>最近踩坑机器学习神经网络中的文本处理,所以有了这篇博客.记录一下基于python word2vec训练中文词向量的方法(英文也同样适用)
<del>虽然事后我发现我需要的并不是词向量word2vec,而是训练获得句子向量的方法,权当做个预告吧(咕咕咕)</del></p></li><li><p>词向量训练:在自然语言处理中将每个单词映射到一个空间向量过程,从而获得每个词汇之间的关联性.(可能说的不太对,大概就这样吧,不是理论帝)</p></li></ul><p><img src=0.jpg alt=" 少数正经的图"></p><h2 id=start><a href=#start class=anchor-link><svg viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96.0-59.27-59.26-59.27-155.7.0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757.0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037.0 01-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482.0 0120.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96.0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454.0 0020.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037.0 00-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639.0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href=#contents:start class=headings>Start</a></h2><ul><li>python:3.5+</li></ul><ol><li><p>安装相应依赖</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>pip install jieba 
</span></span><span class=line><span class=cl>pip install gensim
</span></span></code></pre></td></tr></table></div></div></div><ul><li>jieba用于中文文本分词,英文可直接使用空格分割分词</li><li>gensim词向量训练模块</li></ul></li><li><p>数据预处理</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=k>def</span> <span class=nf>load</span><span class=p>():</span>
</span></span><span class=line><span class=cl>     <span class=n>with</span> <span class=n>open</span><span class=p>(</span><span class=s2>&#34;./train.tsv&#34;</span><span class=p>,</span><span class=s2>&#34;r&#34;</span><span class=p>,</span><span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span> <span class=n>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>         <span class=n>lines</span><span class=o>=</span><span class=n>f</span><span class=o>.</span><span class=n>readlines</span><span class=p>()</span>
</span></span><span class=line><span class=cl>         <span class=n>f</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>         <span class=k>return</span> <span class=n>lines</span>
</span></span><span class=line><span class=cl>     <span class=k>return</span> <span class=n>None</span>
</span></span></code></pre></td></tr></table></div></div></div><p>这里采用的数据格式是以'\t'分割的tsv文件,每一行包含一个句子以及其对应标签.这里将二者共同训练</p></li><li><p>分词并去除停止词</p><ul><li>停止词:指句子中的语气词,特殊符号,数字等对句子意义判别无帮助的词汇,这里推荐几个常用的中文停止词表,你也可以一句自己项目需要自己制作适合的停止词表<a href=https://github.com/goto456/stopwords target=_blank rel=noopener>Github</a></li></ul><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=c1># 导入结巴分词</span>
</span></span><span class=line><span class=cl><span class=n>import</span> <span class=n>jieba</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 读取停止词表函数,停止词表为一行一个的格式</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_stopwords</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>with</span> <span class=n>open</span><span class=p>(</span><span class=s2>&#34;./stopwords.txt&#34;</span><span class=p>,</span><span class=s2>&#34;r&#34;</span><span class=p>,</span><span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span> <span class=n>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>words</span><span class=o>=</span><span class=n>f</span><span class=o>.</span><span class=n>readlines</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>f</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>words</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 装载停止词表</span>
</span></span><span class=line><span class=cl><span class=n>stopowrds</span><span class=o>=</span><span class=n>load_stopwords</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 分词去除停止词函数,lines为上一步中读取的单行数据,将所有的分词保存到文本文件中为下一步训练备用</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>cut</span><span class=p>(</span><span class=n>lines</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>with</span> <span class=n>open</span><span class=p>(</span><span class=s2>&#34;cutwords.txt&#34;</span><span class=p>,</span><span class=s2>&#34;w+&#34;</span><span class=p>,</span><span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span> <span class=n>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>line</span> <span class=ow>in</span> <span class=n>lines</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>words</span><span class=o>=</span><span class=n>jieba</span><span class=o>.</span><span class=n>cut</span><span class=p>(</span><span class=n>line</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1>#去除停止词</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>words</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>stopwords</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>words</span><span class=o>.</span><span class=n>remove</span><span class=p>(</span><span class=n>i</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>words</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>f</span><span class=o>.</span><span class=n>wirte</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div></li><li><p>模型训练</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># 导入词向量训练模块
</span></span><span class=line><span class=cl>from gensim.models import word2vec
</span></span><span class=line><span class=cl>from gensim.models.word2vec import LineSentence
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 训练函数
</span></span><span class=line><span class=cl>def model_train(
</span></span><span class=line><span class=cl>    sentence_in=sentence,   # 需要训练的数据
</span></span><span class=line><span class=cl>    size_in=300,                        # 生成的词向量维数,训练数据量越大,推荐数值越大
</span></span><span class=line><span class=cl>    window_in=5,                        # 滑动窗口大小,涉及到单个词语关联前后单词的数目
</span></span><span class=line><span class=cl>    min_count_in=2,                 # 字典截断,出现次数少于该数值的词汇会被放弃
</span></span><span class=line><span class=cl>    iter_in=5                               # 迭代次数
</span></span><span class=line><span class=cl>    ):
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    print(&#34;start traing...&#34;)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    model=word2vec.Word2Vec(
</span></span><span class=line><span class=cl>    sentences=sentence_in,
</span></span><span class=line><span class=cl>    size=size_in,
</span></span><span class=line><span class=cl>    window=window_in,
</span></span><span class=line><span class=cl>    min_count=min_count_in,
</span></span><span class=line><span class=cl>    workers=multiprocessing.cpu_count(),
</span></span><span class=line><span class=cl>    iter=iter_in
</span></span><span class=line><span class=cl>    )
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    print(&#34;traing complete...&#34;)
</span></span><span class=line><span class=cl>    return model
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 从之前完成分词的数据中装载训练数据,模型sentence参数可以是一个list
</span></span><span class=line><span class=cl># 但是大批量数据时建议使用word2vec自带的类型导入
</span></span><span class=line><span class=cl>sentence=LineSentence(&#34;./cutwords.txt&#34;)
</span></span><span class=line><span class=cl>model=model_train(sentence,300,5,2,5)    
</span></span></code></pre></td></tr></table></div></div></div></li><li><p>保存模型</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># 参数为保存的文件名
</span></span><span class=line><span class=cl>model.save(&#34;modeltest&#34;)
</span></span></code></pre></td></tr></table></div></div></div></li><li><p>模型的二次训练</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=c1># 读取模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>gensim</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>Word2Vec</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;modeltest&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 追加训练</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>more_sentences</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></div></li><li><p>模型使用</p><div class=highlight><div class=chroma><div class=table-container><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># 根据给定的词汇给出10个最相近的词汇
</span></span><span class=line><span class=cl>model.most_similar(&#34;男人&#34;)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 找出离群词
</span></span><span class=line><span class=cl>model.doesnt_match(&#34;测试&#34;)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 计算两个词汇相似度
</span></span><span class=line><span class=cl>model.similarity(&#39;男人&#39;, &#39;女人&#39;) 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 获得单个词汇的词向量
</span></span><span class=line><span class=cl>model[&#39;男人&#39;]
</span></span></code></pre></td></tr></table></div></div></div></li></ol></div><ul class=post-copyright><li class="copyright-item author"><span class=copyright-item-text></span><a href=https://yuukisama.cc/ class="p-author h-card" target=_blank rel=noopener>Yuuki</a></li><li class="copyright-item link"><span class=copyright-item-text></span><a href=/code/word2vec%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/ target=_blank rel=noopener>https://yuukisama.cc/code/word2vec词向量训练/</a></li><li class="copyright-item license"><span class=copyright-item-text></span><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank rel=noopener>CC BY-NC-SA 4.0</a></li></ul></article><div class=updated-badge-container><span title="Updated @ 2024-08-01 07:16:12 UTC" style=cursor:help><svg width="130" height="20" class="updated-badge"><linearGradient id="b" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="a"><rect width="130" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#a)"><path class="updated-badge-left" d="M0 0h55v20H0z"/><path class="updated-badge-right" d="M55 0h75v20H55z"/><path fill="url(#b)" d="M0 0h130v20H0z"/></g><g fill="#fff" text-anchor="middle" font-size="110"><text x="285" y="150" fill="#010101" fill-opacity=".3" textLength="450" transform="scale(.1)">updated</text><text x="285" y="140" textLength="450" transform="scale(.1)">updated</text><text x="915" y="150" fill="#010101" fill-opacity=".3" textLength="650" transform="scale(.1)">2024-08-01</text><text x="915" y="140" textLength="650" transform="scale(.1)">2024-08-01</text></g></svg></span></div><div class=post-share><div class=share-items><div class="share-item facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=https://yuukisama.cc/code/word2vec%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/&amp;hashtag=%23Python" title target=_blank rel=noopener><svg viewBox="0 0 512 512" class="icon facebook-icon"><path d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14.0 55.52 4.84 55.52 4.84v61h-31.28c-30.8.0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg></a></div><div class="share-item mastodon"><a href="/fedishare.html#title=word2vec%e8%af%8d%e5%90%91%e9%87%8f%e8%ae%ad%e7%bb%83&amp;description=%20%e6%a6%82%e8%bf%b0%20%e6%9c%80%e8%bf%91%e8%b8%a9%e5%9d%91%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e4%b8%ad%e7%9a%84%e6%96%87%e6%9c%ac%e5%a4%84%e7%90%86,%e6%89%80%e4%bb%a5%e6%9c%89%e4%ba%86%e8%bf%99%e7%af%87%e5%8d%9a%e5%ae%a2.%e8%ae%b0%e5%bd%95%e4%b8%80%e4%b8%8b%e5%9f%ba%e4%ba%8epython%20word2vec%e8%ae%ad%e7%bb%83%e4%b8%ad%e6%96%87%e8%af%8d%e5%90%91%e9%87%8f%e7%9a%84%e6%96%b9%e6%b3%95%28%e8%8b%b1%e6%96%87%e4%b9%9f%e5%90%8c%e6%a0%b7%e9%80%82%e7%94%a8%29%20%e8%99%bd%e7%84%b6%e4%ba%8b%e5%90%8e%e6%88%91%e5%8f%91%e7%8e%b0%e6%88%91%e9%9c%80%e8%a6%81%e7%9a%84%e5%b9%b6%e4%b8%8d%e6%98%af%e8%af%8d%e5%90%91%e9%87%8fword2vec,%e8%80%8c%e6%98%af%e8%ae%ad%e7%bb%83%e8%8e%b7%e5%be%97%e5%8f%a5%e5%ad%90%e5%90%91%e9%87%8f%e7%9a%84%e6%96%b9%e6%b3%95,%e6%9d%83%e5%bd%93%e5%81%9a%e4%b8%aa%e9%a2%84%e5%91%8a%e5%90%a7%28%e5%92%95%e5%92%95%e5%92%95%29%0a%e8%af%8d%e5%90%91%e9%87%8f%e8%ae%ad%e7%bb%83:%e5%9c%a8%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e4%b8%ad%e5%b0%86%e6%af%8f%e4%b8%aa%e5%8d%95%e8%af%8d%e6%98%a0%e5%b0%84%e5%88%b0%e4%b8%80%e4%b8%aa%e7%a9%ba%e9%97%b4%e5%90%91%e9%87%8f%e8%bf%87%e7%a8%8b,%e4%bb%8e%e8%80%8c%e8%8e%b7%e5%be%97%e6%af%8f%e4%b8%aa%e8%af%8d%e6%b1%87%e4%b9%8b%e9%97%b4%e7%9a%84%e5%85%b3%e8%81%94%e6%80%a7.%28%e5%8f%af%e8%83%bd%e8%af%b4%e7%9a%84%e4%b8%8d%e5%a4%aa%e5%af%b9,%e5%a4%a7%e6%a6%82%e5%b0%b1%e8%bf%99%e6%a0%b7%e5%90%a7,%e4%b8%8d%e6%98%af%e7%90%86%e8%ae%ba%e5%b8%9d%29%0a&amp;url=https://yuukisama.cc/code/word2vec%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/" title target=_blank rel=noopener><svg viewBox="0 0 448 512" class="icon mastodon-icon"><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48.0.0.0-63.72 28.5-63.72 125.7.0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.54 102.54.0 01-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5zm-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg></a></div><div class="share-item fediverse"><a href="/fedishare.html#title=word2vec%e8%af%8d%e5%90%91%e9%87%8f%e8%ae%ad%e7%bb%83&amp;description=%20%e6%a6%82%e8%bf%b0%20%e6%9c%80%e8%bf%91%e8%b8%a9%e5%9d%91%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e4%b8%ad%e7%9a%84%e6%96%87%e6%9c%ac%e5%a4%84%e7%90%86,%e6%89%80%e4%bb%a5%e6%9c%89%e4%ba%86%e8%bf%99%e7%af%87%e5%8d%9a%e5%ae%a2.%e8%ae%b0%e5%bd%95%e4%b8%80%e4%b8%8b%e5%9f%ba%e4%ba%8epython%20word2vec%e8%ae%ad%e7%bb%83%e4%b8%ad%e6%96%87%e8%af%8d%e5%90%91%e9%87%8f%e7%9a%84%e6%96%b9%e6%b3%95%28%e8%8b%b1%e6%96%87%e4%b9%9f%e5%90%8c%e6%a0%b7%e9%80%82%e7%94%a8%29%20%e8%99%bd%e7%84%b6%e4%ba%8b%e5%90%8e%e6%88%91%e5%8f%91%e7%8e%b0%e6%88%91%e9%9c%80%e8%a6%81%e7%9a%84%e5%b9%b6%e4%b8%8d%e6%98%af%e8%af%8d%e5%90%91%e9%87%8fword2vec,%e8%80%8c%e6%98%af%e8%ae%ad%e7%bb%83%e8%8e%b7%e5%be%97%e5%8f%a5%e5%ad%90%e5%90%91%e9%87%8f%e7%9a%84%e6%96%b9%e6%b3%95,%e6%9d%83%e5%bd%93%e5%81%9a%e4%b8%aa%e9%a2%84%e5%91%8a%e5%90%a7%28%e5%92%95%e5%92%95%e5%92%95%29%0a%e8%af%8d%e5%90%91%e9%87%8f%e8%ae%ad%e7%bb%83:%e5%9c%a8%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e4%b8%ad%e5%b0%86%e6%af%8f%e4%b8%aa%e5%8d%95%e8%af%8d%e6%98%a0%e5%b0%84%e5%88%b0%e4%b8%80%e4%b8%aa%e7%a9%ba%e9%97%b4%e5%90%91%e9%87%8f%e8%bf%87%e7%a8%8b,%e4%bb%8e%e8%80%8c%e8%8e%b7%e5%be%97%e6%af%8f%e4%b8%aa%e8%af%8d%e6%b1%87%e4%b9%8b%e9%97%b4%e7%9a%84%e5%85%b3%e8%81%94%e6%80%a7.%28%e5%8f%af%e8%83%bd%e8%af%b4%e7%9a%84%e4%b8%8d%e5%a4%aa%e5%af%b9,%e5%a4%a7%e6%a6%82%e5%b0%b1%e8%bf%99%e6%a0%b7%e5%90%a7,%e4%b8%8d%e6%98%af%e7%90%86%e8%ae%ba%e5%b8%9d%29%0a&amp;url=https://yuukisama.cc/code/word2vec%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/" title target=_blank rel=noopener><svg viewBox="64 163 873 873" class="icon fediverse-icon"><defs><linearGradient id="fediverse-gradient"><stop offset="0" stop-color="#ff0101"/><stop offset="10%" stop-color="#9501ff"/><stop offset="50%" stop-color="#ffca01"/><stop offset="75%" stop-color="#01a3ff"/><stop offset="100%" stop-color="#65ff01"/></linearGradient></defs><path d="M539 176q-32 0-55 22t-25 55 20.5 58 56 27 58.5-20.5 27-56-20.5-59T544 176h-5zm-87 95-232 118q20 20 25 48l231-118q-19-20-24-48zm167 27q-13 25-38 38l183 184q13-25 39-38zM477 320 342 585l40 40 143-280q-28-5-48-25zm104 16q-22 11-46 10l-8-1 21 132 56 9zM155 370q-32 0-55 22.5t-25 55 20.5 58 56.5 27 59-21 26.5-56-21-58.5-55.5-27h-6zm90 68q1 9 1 18-1 19-10 35l132 21 26-50zm225 36-26 51 311 49q-1-8-1-17 1-19 10-36zm372 6q-32 1-55 23t-24.5 55 21 58 56 27 58.5-20.5 27-56.5-20.5-59-56.5-27h-6zM236 493q-13 25-39 38l210 210 51-25zm-40 38q-21 11-44 10l-9-1 40 256q21-10 45-9l8 1zm364 22 48 311q21-10 44-9l10 1-46-294zm195 23-118 60 8 56 135-68q-20-20-25-48zm26 49-119 231q28 5 48 25l119-231q-28-5-48-25zM306 654l-68 134q28 5 48 25l60-119zm262 17-281 143q19 20 24 48l265-135zM513 771l-51 25 106 107q13-25 39-38zM222 795q-32 0-55.5 22.5t-25 55 21 57.5 56 27 58.5-20.5 27-56-20.5-58.5-56.5-27h-5zm89 68q2 9 1 18-1 19-9 35l256 41q-1-9-1-18 1-18 10-35zm335 0q-32 0-55 22.5t-24.5 55 20.5 58 56 27 59-21 27-56-20.5-58.5-56.5-27h-6z"/></svg></a></div><div class="share-item twitter"><a href="https://twitter.com/share?url=https://yuukisama.cc/code/word2vec%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/&amp;text=word2vec%e8%af%8d%e5%90%91%e9%87%8f%e8%ae%ad%e7%bb%83&amp;hashtags=Python,%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0,&amp;via=yukiricc" title target=_blank rel=noopener><svg viewBox="0 0 512 512" class="icon twitter-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a></div></div></div><div class=related-posts><h2 class=related-title><svg viewBox="0 0 512 512" class="icon related-icon"><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm144 276c0 6.6-5.4 12-12 12h-92v92c0 6.6-5.4 12-12 12h-56c-6.6.0-12-5.4-12-12v-92h-92c-6.6.0-12-5.4-12-12v-56c0-6.6 5.4-12 12-12h92v-92c0-6.6 5.4-12 12-12h56c6.6.0 12 5.4 12 12v92h92c6.6.0 12 5.4 12 12v56z"/></svg></h2><ul class=related-list><li class=related-item><a href=/code/2019%E4%BF%A1%E5%AE%89%E5%9B%BD%E8%B5%9B%E5%87%BA%E9%A2%98%E7%BB%8F%E5%8E%86/ class=related-link>2019信安国赛出题经历</a></li><li class=related-item><a href=/code/python-requests-ssl%E6%8A%A5%E9%94%99/ class=related-link>Python requests ssl报错</a></li><li class=related-item><a href=/code/%E9%AB%98%E9%98%B6%E7%88%AC%E8%99%ABselenium%E6%91%98%E8%AE%B0/ class=related-link>高阶爬虫selenium摘记</a></li><li class=related-item><a href=/code/python%E5%B8%B8%E7%94%A8skill/ class=related-link>Python常用Skill</a></li><li class=related-item><a href=/code/mysql%E5%AF%86%E7%A0%81%E9%87%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/ class=related-link>MYSQL密码重置详解</a></li></ul></div><div class=post-tags><a href=/tags/python/ rel=tag class=post-tags-link><svg viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49.0 48 0h204.118a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137.0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882.0L14.059 286.059A48 48 0 010 252.118zM112 64c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>Python</a>
<a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ rel=tag class=post-tags-link><svg viewBox="0 0 512 512" class="icon tag-icon"><path d="M0 252.118V48C0 21.49 21.49.0 48 0h204.118a48 48 0 0133.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137.0 67.882L293.823 497.941c-18.745 18.745-49.137 18.745-67.882.0L14.059 286.059A48 48 0 010 252.118zM112 64c-26.51.0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48z"/></svg>机器学习</a></div><footer class=minimal-footer><div class=post-tag><a href=/tags/python/ rel=tag class=post-tag-link>#python</a> <a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ rel=tag class=post-tag-link>#机器学习</a></div><div class=post-category><a href=/code/ class=post-category-link>code</a></div></footer><ul class=post-nav><li class=post-nav-prev><a href=/code/c%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E7%B2%BE%E7%82%BC/ rel=prev>&lt; C语言基础精炼</a></li><li class=post-nav-next><a href=/code/%E9%AB%98%E9%98%B6%E7%88%AC%E8%99%ABselenium%E6%91%98%E8%AE%B0/ rel=next>高阶爬虫selenium摘记 ></a></li></ul><div id=utterances></div></div></main><div id=back-to-top class=back-to-top><a href=#><svg viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6.0-33.9L207 39c9.4-9.4 24.6-9.4 33.9.0l194.3 194.3c9.4 9.4 9.4 24.6.0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3.0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a></div><footer id=footer class=footer><div class=footer-inner><div class=site-info><span class=copyleft-symbol>🄯</span>&nbsp;©&nbsp;2017–2024&nbsp;<svg viewBox="0 0 512 512" class="icon footer-icon"><path d="M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3.0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z"/></svg></div><div class=site-copyright><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh target=_blank rel=noopener>CC BY-NC-SA 4.0</a></div><div class=busuanzi-site-uv-and-pv><span id=busuanzi_container_site_uv>本站访客数&nbsp;<svg viewBox="0 0 448 512" class="icon busuanzi-site-uv"><path d="M224 256c70.7.0 128-57.3 128-128S294.7.0 224 0 96 57.3 96 128s57.3 128 128 128zm89.6 32h-16.7c-22.2 10.2-46.9 16-72.9 16s-50.6-5.8-72.9-16h-16.7C60.2 288 0 348.2.0 422.4V464c0 26.5 21.5 48 48 48h352c26.5.0 48-21.5 48-48v-41.6c0-74.2-60.2-134.4-134.4-134.4z"/></svg>&nbsp;<span id=busuanzi_value_site_uv></span></span>&nbsp;|&nbsp;<span id=busuanzi_container_site_pv>本站访问量&nbsp;<svg viewBox="0 0 576 512" class="icon busuanzi-site-pv"><path d="M288 144a110.94 110.94.0 00-31.24 5 55.4 55.4.0 017.24 27 56 56 0 01-56 56 55.4 55.4.0 01-27-7.24A111.71 111.71.0 10288 144zm284.52 97.4C518.29 135.59 410.93 64 288 64S57.68 135.64 3.48 241.41a32.35 32.35.0 000 29.19C57.71 376.41 165.07 448 288 448s230.32-71.64 284.52-177.41a32.35 32.35.0 000-29.19zM288 4e2c-98.65.0-189.09-55-237.93-144C98.91 167 189.34 112 288 112s189.09 55 237.93 144C477.1 345 386.66 4e2 288 4e2z"/></svg>&nbsp;<span id=busuanzi_value_site_pv></span></span></div><ul class=socials><li class=socials-item><a href=/rss.xml target=_blank rel="external noopener" title=RSS><svg viewBox="0 0 24 24" class="icon social-icon"><path d="M19.199 24C19.199 13.467 10.533 4.8.0 4.8V0c13.165.0 24 10.835 24 24h-4.801zM3.291 17.415c1.814.0 3.293 1.479 3.293 3.295.0 1.813-1.485 3.29-3.301 3.29C1.47 24 0 22.526.0 20.71s1.475-3.294 3.291-3.295zM15.909 24h-4.665c0-6.169-5.075-11.245-11.244-11.245V8.09c8.727.0 15.909 7.184 15.909 15.91z"/></svg></a></li><li class=socials-item><a href=mailto:chainyuuki@gmail.com target=_blank rel="external noopener" title=Email><svg viewBox="0 0 512 512" class="icon social-icon"><path d="M464 64H48C21.49 64 0 85.49.0 112v288c0 26.51 21.49 48 48 48h416c26.51.0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 4e2V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V4e2H48z"/></svg></a></li><li class=socials-item><a href=https://github.com/needhourger target=_blank rel="external noopener" title=GitHub><svg viewBox="0 0 24 24" class="icon social-icon"><path d="M12 .297c-6.63.0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577.0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93.0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176.0.0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22.0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22.0 1.606-.015 2.896-.015 3.286.0.315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a></li><li class=socials-item><a href=https://twitter.com/yukiricc target=_blank rel="external noopener" title=Twitter><svg viewBox="0 0 512 512" class="icon social-icon"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645.0 138.72-105.583 298.558-298.558 298.558-59.452.0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055.0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421.0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391.0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04.0-57.828 46.782-104.934 104.934-104.934 30.213.0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg></a></li><li class=socials-item><a href=https://t.me/Ceil_Chan target=_blank rel="external noopener" title=Telegram><svg viewBox="0 0 496 512" class="icon social-icon"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm121.8 169.9-40.7 191.8c-3 13.6-11.1 16.9-22.4 10.5l-62-45.7-29.9 28.8c-3.3 3.3-6.1 6.1-12.5 6.1l4.4-63.1 114.9-103.8c5-4.4-1.1-6.9-7.7-2.5l-142 89.4-61.2-19.1c-13.3-4.2-13.6-13.3 2.8-19.7l239.1-92.2c11.1-4 20.8 2.7 17.2 19.5z"/></svg></a></li></ul></div></footer></div><script>function loadComments(){(function(){const t=document.getElementById("utterances");if(!t)return;const e=document.createElement("script");e.src="https://utteranc.es/client.js",e.async=!0,e.crossOrigin="anonymous",e.setAttribute("repo","needhourger/needhourger.github.io"),e.setAttribute("issue-term","pathname");const n=getCurrentTheme()==="dark";n?e.setAttribute("theme","photon-dark"):e.setAttribute("theme","preferred-color-scheme"),e.setAttribute("label","💬"),t.appendChild(e)})()}</script><script src=https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js></script><script>let imgNodes=document.querySelectorAll("div.post-body img");imgNodes=Array.from(imgNodes).filter(e=>e.parentNode.tagName!=="A"),mediumZoom(imgNodes,{background:"hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)"})</script><script src=https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js type=module defer></script><script async src=https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>